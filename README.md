<h2>Language Grounding to Vision and Control Papers </h2>



<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(1).pdf" style="text-decoration:none;">Symbolic Priors for RNN-based Semantic Parsing</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(2).pdf" style="text-decoration:none;">From Machine Learning to Machine Reasoning</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(3).pdf" style="text-decoration:none;">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(4).pdf" style="text-decoration:none;">Traversing Knowledge Graphs in Vector Space</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(5).pdf" style="text-decoration:none;">Generation and Comprehension of Unambiguous Object Descriptions</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(6).pdf" style="text-decoration:none;">Segmentation from Natural Language Expressions</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(7).pdf" style="text-decoration:none;">A Neural Knowledge Language Model</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(8).pdf" style="text-decoration:none;"> Navigational Instruction Generation as Inverse Reinforcement Learning with Neural Machine Translation </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(9).pdf" style="text-decoration:none;">Differentiable Learning of Logical Rules for Knowledge Base Reasoning</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(10).pdf" style="text-decoration:none;">Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning </a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(11).pdf" style="text-decoration:none;">Translating Neuralese</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(12).pdf" style="text-decoration:none;">A simple neural network module for relational reasoning</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(13).pdf" style="text-decoration:none;">Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(14).pdf" style="text-decoration:none;">Attention Is All You Need</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(15).pdf" style="text-decoration:none;">Deal or No Deal? End-to-End Learning for Negotiation Dialogues</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(16).pdf" style="text-decoration:none;">Evaluating Visual Conversational Agents via Cooperative Human-AI Games</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(17).pdf" style="text-decoration:none;">Multimodal Distributional Semantics</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(18).pdf" style="text-decoration:none;">Learning to Interpret Natural Language Navigation Instructions from Observations</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(19).pdf" style="text-decoration:none;">Word learning as Bayesian inference</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(20).pdf" style="text-decoration:none;">Imagined Visual Representations as Multimodal Embeddings</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(21).pdf" style="text-decoration:none;">Deep Visual-Semantic Alignments for Generating Image Descriptions</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(22).pdf" style="text-decoration:none;">Representing Text for Joint Embedding of Text and Knowledge Bases</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(23).pdf" style="text-decoration:none;">Deep Neural Networks with Massive Learned Knowledge</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(24).pdf" style="text-decoration:none;">Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(25).pdf" style="text-decoration:none;">Environment-Driven Lexicon Induction for High-Level Instructions</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(26).pdf" style="text-decoration:none;">Executable Semantic Parsing</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(27).pdf" style="text-decoration:none;">Learning Executable Semantic Parsers for Natural Language Understanding</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(28).pdf" style="text-decoration:none;">Generating Visual Explanations</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(29).pdf" style="text-decoration:none;">The Symbol Grounding Problem </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(30).pdf" style="text-decoration:none;">A Natural Language Planner Interface for Mobile Manipulators</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(31).pdf" style="text-decoration:none;">Intuitive theories</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(32).pdf" style="text-decoration:none;">Leveraging Knowledge Bases in LSTMs for Improving Machine Reading</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(33).pdf" style="text-decoration:none;">Weakly Supervised Training of Semantic Parsers</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(34).pdf" style="text-decoration:none;">Language to Logical Form with Neural Attention</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(35).pdf" style="text-decoration:none;">Learning Continuous Semantic Representations of Symbolic Expressions</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(36).pdf" style="text-decoration:none;">Learning Graphical State Transitions </a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(37).pdf" style="text-decoration:none;">Language Grounding to Vision and Control: Introduction</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(38).pdf" style="text-decoration:none;">Tracking by Natural Language Specification</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(39).pdf" style="text-decoration:none;">Human-in-the-Loop Parsing</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(40).pdf" style="text-decoration:none;">How language programs the mind</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(41).pdf" style="text-decoration:none;">Differentiable Programs with Neural Libraries</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(42).pdf" style="text-decoration:none;">Tell Me Dave: Context-Sensitive Grounding of Natural Language to Manipulation Instructions</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(43).pdf" style="text-decoration:none;">Mapping Instructions and Visual Observations to Actions with Reinforcement Learning</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(44).pdf" style="text-decoration:none;">Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(45).pdf" style="text-decoration:none;">The Need for Biases in Learning Generalizations</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(46).pdf" style="text-decoration:none;">Deep Recursive Neural Networks for Compositionality in Language</a></li> 
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(47).pdf" style="text-decoration:none;">End-To-End Memory Networks</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(48).pdf" style="text-decoration:none;">Unsupervised Learning by Program Synthesis</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(49).pdf" style="text-decoration:none;">Program Synthesis using Natural Language</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(50).pdf" style="text-decoration:none;">Pointer Networks: Handling variable size output dictionary</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(51).pdf" style="text-decoration:none;">Recursive Neural Networks Can Learn Logical Semantics</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(52).pdf" style="text-decoration:none;">Situation Recognition: Visual Semantic Role Labeling for Image Understanding</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(53).pdf" style="text-decoration:none;">Guiding Interaction Behaviors for Multi-modal Grounded Language Learning</a></li>
 
<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(54).pdf" style="text-decoration:none;">Theory-based Bayesian models of inductive learning and reasoning </a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(55).pdf" style="text-decoration:none;">Learning Knowledge Base Inference with Neural Theorem Provers</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(56).pdf" style="text-decoration:none;">Building a Semantic Parser Overnight </a></li>                              

<li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(57).pdf" style="text-decoration:none;">Natural Language Acquisition and Grounding for Embodied Robotic Systems</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(58).pdf" style="text-decoration:none;">Grounded Language Learning: Where Robotics and NLP Meet</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(59).pdf" style="text-decoration:none;">Grounding language acquisition by training semantic parsers using captioned videos</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(60).pdf" style="text-decoration:none;">A Short review of Symbol Grounding in Robotic and Intelligent Systems </a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(61).pdf" style="text-decoration:none;">Tell Me Dave: Context-Sensitive Grounding of Natural Language to Manipulation Instructions</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Language-Grounding-to-Vision-and-Control-Papers/blob/master/lg(62).pdf" style="text-decoration:none;"> Counterfactual Contrastive Learning for Weakly-Supervised Vision-Language Grounding</a></li>
 






  </ul>
